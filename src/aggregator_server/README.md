# Aggregator server

- Verifies `N` proofs generated by zeth prover, and generates a proof of CI that the `N` proofs have been verified.
- Note that the verifier gadget for GROTH16 is not implemented in libsnark
    - Thus, we can't recurse with groth16, and I need to use pghr13 for now

## TODO

- [ ] Switch zeth proofs to be generated over MNT6 
- [ ] Implement proof aggregator functionality to verify `N` proofs over MNT6, and generate a proof of CI of the verification over MNT4
- [ ] Before diving into RPC interfaces, test the recursion with unit tests for the aggregator, in which we generate `N` zeth proofs with the zeth proof generator, and in which we verify them. Then, and only then, we can step up the game and start to use different components communicating with RPC messages.
    - [ ] For this to work, it may be necessary to support "batch" verification in the circuit. As such, it is necessary to modify the verifier circuit to support batching. Otherwise, we can just call multiple "verifier" gadgets to verify multiple proofs sequentially, and the "aggregation circuit" would be said to be satisfied if ALL verifiers have successfully been evaluated => The advantage of this approach (as opposed to batching is that we can then identify which zeth proof was not succesfully verified)
    => The format of the `data` field of an aggregate transaction would be something like:
    ```json
        data: {
            zeth_txs:[
                    1: {
                        verified: bool, // boolean indicating if the associated proof was succesfully verified (i.e. "would this tx have been considered valid by the mixer snark verification procedure")
                        nullifiers: [nf1, nf2], // The list of nullifiers spent by the zeth tx
                        commitments: [cm1, cm2] // The list of commitments created by the zeth tx
                        ciphertexts: [cp1, cp2] // The list of  ciphertexts created by the zeth tx
                        ephk: [] //  the ephemeral keys used to generate the ciphertexts
                        hsig // may be necessary to have hsig and vk too in order to verify the otschnorr
                        vk
                    },
                    2: {
                        ...
                    }
                    ...
                    N:{...}
                ]
            }
        }
    ```
    - By passing the result of the verification to the mixer directly, we save a lot of gas on-chain, because we dont need to verify all the `N` proofs, bu we just need to verify the `aggregate_proof`, and the rest consist in checking the `zeth_txs` of the `data`, and this is just checking the nullifiers of each tx, appending the commitments to the tree, once all commitments have been appended to the tree, we recompute the root, and emit the data (commitments, nullifiers, ciphertexts) => emitting batch of data like that is quite good from a leakage "control" perspective, since now the recipient listen and fetches batch of events instead of individual events.
- [ ] Implement RPC interface for the proof aggregator, in order to be able to receive the proofs to be aggregated, populate them in a "zeth tx pool", and verify batches of `N` proofs.
    - [ ] Also include an endpoint to receive the nested vk from the zeth prover
- [ ] Support MNT4 operations on-chain to be able to carry out the verification of the aggregate snark
    - [ ] Implement a set of precompiled contracts to be able to do the arithmetic over MNT4

### Misc

- [ ] Switch from MNT-cycles to Cocks-Pinch like in Zexe, and use the "single-hop" recursion to do a batch verification of the `N` zeth proofs.
    - Use BLS12-377 and the Cocks-Pinch curve of Zexe
        - [ ] Implement a set of precompiled contracts to be able to carry out the verification on-chain
        - [ ] Implement the curve arithmetic in c++ to use on the prover side
- [ ] Implement the groth16 verifier gagdet in libsnark
    - This may be a bit more tricky than expected:
        - Since we have modified groth16 to match the mpc implementation, and remove the element of Gt from the key because we can't manipulate elements of Gt on-chain; we will need to implement OUR custom groth16 verification inside the circuit
- [ ] Implement the full Zeth transaction verification process in a circuit in order to verify that each transaction is valid
    - In other words, it is necessary to implement "all the mixer logic" in a circuit in order to verify the validity of the zeth transactions that are "batched"
    - Importantly, it may NOT be necessary to verify the ECDSA sigs and so on in the aggregator circuit, because the aggregator server does not actually aggregate ETHEREUM transactions, but rather aggregates ZETH transactions (i.e. emitted by Zeth users). As such, it is only necessary for the Aggregator to carry out the verification checks of Zeth. Additionally, if we have some sort of incentive structure to reward the aggregator, carrying out the entire verification routine of zeth in the aggregation circuit will be all the more important as the aggregator only may only want settling valid tx on-chain to unlock his reward = although this can pose several issues related to censorship => it may be useful to settle invalid tx on-chain for the sake of validiting and proving to a user that his tx was processed but invalid.

- [ ] Explicit the incentive structure behind the aggregation. Validators/miners on the network all deposit a fixed reward on a smart contract. This reward pool is dedicated to reward aggregator servers for their work. By aggregating txs and settling the proof of aggregation on-chain, they generate positive extrernalities on the network because they compress a set of zeth tx into a single big tx which is strictly smaller than the sum of the size of all the transactions. As such, they compress data by their action of aggregating, and they save storage on the validator nodes. They should be rewarded for doing that. Their reward is taken from the reward pool constituted by the validator nodes.
    - Thus the aggregator ultimately receives a reward coming from all the validators on the system
    - If a Relay is doing aggregation, the Relay will receive the Relay fee (for settling the cash payment on-chain), and the Aggregation fee (for compressing data before it goes on chain).

- [ ] Define the compression rate of the aggregator as ((\sum size of input Zeth tx) / (size of aggregation tx)), we can add this aggregation rate to the `aggregator_server` code, and log it

- [ ] Use Zeth as a submodule after:
    - The PR on the underflow has been merged (which should solve the issue with the number of primary inputs)
    - The Functions working only with alt_bn128 have been generalized (functions related to file manipulation and "dump" of proofs and inputs)